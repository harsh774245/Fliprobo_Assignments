{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "filename='assign_3_data.zip'\n",
    "with ZipFile(filename,'r') as file:\n",
    "    file.extractall()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
    "from keras import backend as k\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               34669056  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 34,763,843\n",
      "Trainable params: 34,763,843\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "model1.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "model1.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1.compile(SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('assign_3_data/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('assign_3_data/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "cb1=callbacks.ModelCheckpoint('m1cp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es1= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=4,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro1=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.002, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - 20s 91ms/step - loss: 0.7067 - accuracy: 0.6650 - val_loss: 0.3342 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33425, saving model to m1cp.h5\n",
      "Epoch 2/20\n",
      "225/225 [==============================] - 20s 90ms/step - loss: 0.2492 - accuracy: 0.9031 - val_loss: 0.4200 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.33425\n",
      "Epoch 3/20\n",
      "225/225 [==============================] - 20s 90ms/step - loss: 0.1273 - accuracy: 0.9519 - val_loss: 0.0849 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33425 to 0.08491, saving model to m1cp.h5\n",
      "Epoch 4/20\n",
      "225/225 [==============================] - 21s 91ms/step - loss: 0.0701 - accuracy: 0.9753 - val_loss: 0.2746 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08491\n",
      "Epoch 5/20\n",
      "225/225 [==============================] - 20s 90ms/step - loss: 0.0659 - accuracy: 0.9731 - val_loss: 0.0825 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08491 to 0.08251, saving model to m1cp.h5\n",
      "Epoch 6/20\n",
      "225/225 [==============================] - 20s 91ms/step - loss: 0.0217 - accuracy: 0.9917 - val_loss: 0.0046 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.08251 to 0.00458, saving model to m1cp.h5\n",
      "Epoch 7/20\n",
      "225/225 [==============================] - 20s 91ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9347 - val_accuracy: 0.9496\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00458\n",
      "Epoch 8/20\n",
      "225/225 [==============================] - 20s 90ms/step - loss: 8.7364e-04 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00458\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.9999999552965164e-05.\n",
      "Epoch 9/20\n",
      "225/225 [==============================] - 20s 90ms/step - loss: 5.8594e-04 - accuracy: 1.0000 - val_loss: 1.9919 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00458\n",
      "Epoch 10/20\n",
      "225/225 [==============================] - 20s 91ms/step - loss: 5.8761e-04 - accuracy: 1.0000 - val_loss: 2.0675 - val_accuracy: 0.9501\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00458\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.9999998989515006e-08.\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1=model1.fit_generator(train_set,\n",
    "                             steps_per_epoch=3600//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1,cb1,ro1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image=cv2.imread('tshirt.jpeg')\n",
    "# image=cv2.resize(image, (200,200), interpolation=cv2.INTER_AREA)\n",
    "# image=image.reshape(1,200,200,3)\n",
    "# res=model1.predict_classes(image,1,verbose=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 21, 21, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 3,518,659\n",
      "Trainable params: 3,518,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1a=Sequential()\n",
    "model1a.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1a.add(MaxPooling2D(2,2))\n",
    "model1a.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1a.add(MaxPooling2D(2,2))\n",
    "model1a.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1a.add(MaxPooling2D(2,2))\n",
    "model1a.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1a.add(MaxPooling2D(2,2))\n",
    "model1a.add(Dropout(0.3))\n",
    "\n",
    "model1a.add(Flatten())\n",
    "\n",
    "model1a.add(Dense(256, activation='relu'))\n",
    "model1a.add(Dropout(0.25))\n",
    "model1a.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1a.compile(SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set1a = train_datagen.flow_from_directory('assign_3_data/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=32,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set1a = test_datagen.flow_from_directory('assign_3_data/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=32,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "cb1a=callbacks.ModelCheckpoint('m1acp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es1a= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=4,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro1a=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.002, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.8116 - accuracy: 0.5973 - val_loss: 0.4339 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43390, saving model to m1acp.h5\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.4586 - accuracy: 0.8013 - val_loss: 0.2116 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43390 to 0.21157, saving model to m1acp.h5\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.2895 - accuracy: 0.8845 - val_loss: 0.1570 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21157 to 0.15697, saving model to m1acp.h5\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.1904 - accuracy: 0.9238 - val_loss: 0.1216 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15697 to 0.12158, saving model to m1acp.h5\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.1374 - accuracy: 0.9462 - val_loss: 0.3996 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12158\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.1197 - accuracy: 0.9529 - val_loss: 0.1088 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12158 to 0.10880, saving model to m1acp.h5\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.0861 - accuracy: 0.9675 - val_loss: 0.2395 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10880\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.0755 - accuracy: 0.9725 - val_loss: 0.0906 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10880 to 0.09057, saving model to m1acp.h5\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.0560 - accuracy: 0.9773 - val_loss: 0.4159 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09057\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 0.2694 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09057\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.9999999552965164e-05.\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.0843 - accuracy: 0.9775 - val_loss: 0.3295 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.09057\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.0699 - accuracy: 0.9784 - val_loss: 0.5060 - val_accuracy: 0.9167\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09057\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.9999998989515006e-08.\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1a=model1a.fit_generator(train_set1a,\n",
    "                             steps_per_epoch=3600//32,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set1a,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1a,cb1a,ro1a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1b=Sequential()\n",
    "model1b.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1b.add(MaxPooling2D(2,2))\n",
    "model1b.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1b.add(MaxPooling2D(2,2))\n",
    "model1b.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1b.add(MaxPooling2D(2,2))\n",
    "model1b.add(Dropout(0.3))\n",
    "\n",
    "model1b.add(Flatten())\n",
    "\n",
    "model1b.add(Dense(128, activation='relu'))\n",
    "model1b.add(Dropout(0.25))\n",
    "model1b.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1b.compile(SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set1b = train_datagen.flow_from_directory('assign_3_data/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=32,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set1b = test_datagen.flow_from_directory('assign_3_data/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=32,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "cb1b=callbacks.ModelCheckpoint('m1bcp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es1b= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=4,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro1b=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.02, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.7021 - accuracy: 0.6651 - val_loss: 0.3680 - val_accuracy: 0.7667\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36797, saving model to m1bcp.h5\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.3638 - accuracy: 0.8439 - val_loss: 0.1789 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.36797 to 0.17888, saving model to m1bcp.h5\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.2147 - accuracy: 0.9081 - val_loss: 0.1980 - val_accuracy: 0.9667\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17888\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 0.1468 - accuracy: 0.9400 - val_loss: 0.1161 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17888 to 0.11614, saving model to m1bcp.h5\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 0.1054 - accuracy: 0.9599 - val_loss: 0.3148 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11614\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.0873 - accuracy: 0.9672 - val_loss: 0.1933 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11614\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00019999999552965166.\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.0576 - accuracy: 0.9798 - val_loss: 0.1581 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11614\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.0334 - accuracy: 0.9874 - val_loss: 0.2225 - val_accuracy: 0.9500\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11614\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1b=model1b.fit_generator(train_set1b,\n",
    "                             steps_per_epoch=3600//32,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set1b,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1b,cb1b,ro1b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1c=Sequential()\n",
    "model1c.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1c.add(MaxPooling2D(2,2))\n",
    "model1c.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1c.add(MaxPooling2D(2,2))\n",
    "model1c.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1c.add(MaxPooling2D(2,2))\n",
    "model1c.add(Dropout(0.3))\n",
    "\n",
    "model1c.add(Flatten())\n",
    "\n",
    "model1c.add(Dense(128, activation='relu'))\n",
    "model1c.add(Dropout(0.25))\n",
    "model1c.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1c.compile(SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set1c = train_datagen.flow_from_directory('assign_3_data/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=64,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set1c = test_datagen.flow_from_directory('assign_3_data/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=64,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "cb1c=callbacks.ModelCheckpoint('m1ccp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es1c= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=5,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro1c=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "56/56 [==============================] - 42s 748ms/step - loss: 0.7644 - accuracy: 0.6210 - val_loss: 0.6812 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68116, saving model to m1ccp.h5\n",
      "Epoch 2/20\n",
      "56/56 [==============================] - 43s 762ms/step - loss: 0.4694 - accuracy: 0.7916 - val_loss: 0.2844 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68116 to 0.28438, saving model to m1ccp.h5\n",
      "Epoch 3/20\n",
      "56/56 [==============================] - 43s 766ms/step - loss: 0.2698 - accuracy: 0.8863 - val_loss: 0.1590 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.28438 to 0.15895, saving model to m1ccp.h5\n",
      "Epoch 4/20\n",
      "56/56 [==============================] - 42s 752ms/step - loss: 0.1887 - accuracy: 0.9200 - val_loss: 0.1631 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15895\n",
      "Epoch 5/20\n",
      "56/56 [==============================] - 42s 751ms/step - loss: 0.1361 - accuracy: 0.9463 - val_loss: 0.1900 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15895\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999776482583e-05.\n",
      "Epoch 6/20\n",
      "56/56 [==============================] - 43s 764ms/step - loss: 0.3514 - accuracy: 0.8886 - val_loss: 0.2567 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15895\n",
      "Epoch 7/20\n",
      "56/56 [==============================] - 43s 763ms/step - loss: 0.1487 - accuracy: 0.9395 - val_loss: 0.2139 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15895\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 8/20\n",
      "56/56 [==============================] - 41s 740ms/step - loss: 0.1224 - accuracy: 0.9538 - val_loss: 0.2164 - val_accuracy: 0.9000\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15895\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1c=model1c.fit_generator(train_set1c,\n",
    "                             steps_per_epoch=3600//64,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set1c,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1c,cb1c,ro1c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1d=Sequential()\n",
    "model1d.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1d.add(MaxPooling2D(2,2))\n",
    "model1d.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1d.add(MaxPooling2D(2,2))\n",
    "model1d.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1d.add(MaxPooling2D(2,2))\n",
    "model1d.add(Dropout(0.3))\n",
    "\n",
    "model1d.add(Flatten())\n",
    "\n",
    "model1d.add(Dense(128, activation='relu'))\n",
    "model1d.add(Dropout(0.25))\n",
    "model1d.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1d.compile(SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set1d = train_datagen.flow_from_directory('assign_3_data/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set1d = test_datagen.flow_from_directory('assign_3_data/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "cb1d=callbacks.ModelCheckpoint('m1dcp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es1d= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=5,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro1d=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - 20s 88ms/step - loss: 0.7771 - accuracy: 0.6189 - val_loss: 0.3986 - val_accuracy: 0.8334\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39860, saving model to m1dcp.h5\n",
      "Epoch 2/20\n",
      "225/225 [==============================] - 19s 83ms/step - loss: 0.3974 - accuracy: 0.8256 - val_loss: 0.3308 - val_accuracy: 0.8999\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39860 to 0.33081, saving model to m1dcp.h5\n",
      "Epoch 3/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.2328 - accuracy: 0.9047 - val_loss: 0.0936 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33081 to 0.09363, saving model to m1dcp.h5\n",
      "Epoch 4/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.1482 - accuracy: 0.9414 - val_loss: 0.2442 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09363\n",
      "Epoch 5/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.1115 - accuracy: 0.9572 - val_loss: 0.0754 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.09363 to 0.07535, saving model to m1dcp.h5\n",
      "Epoch 6/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.0887 - accuracy: 0.9683 - val_loss: 0.0031 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07535 to 0.00315, saving model to m1dcp.h5\n",
      "Epoch 7/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.0620 - accuracy: 0.9753 - val_loss: 0.0145 - val_accuracy: 0.9667\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00315\n",
      "Epoch 8/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.0469 - accuracy: 0.9842 - val_loss: 0.0247 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00315\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999776482583e-05.\n",
      "Epoch 9/20\n",
      "225/225 [==============================] - 19s 83ms/step - loss: 0.0461 - accuracy: 0.9839 - val_loss: 0.4143 - val_accuracy: 0.9502\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00315\n",
      "Epoch 10/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.0295 - accuracy: 0.9883 - val_loss: 0.5650 - val_accuracy: 0.9666\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00315\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 11/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.0265 - accuracy: 0.9900 - val_loss: 0.1634 - val_accuracy: 0.9667\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00315\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1d=model1d.fit_generator(train_set1d,\n",
    "                             steps_per_epoch=3600//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set1d,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1d,cb1d,ro1d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1e=Sequential()\n",
    "model1e.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1e.add(MaxPooling2D(2,2))\n",
    "model1e.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1e.add(MaxPooling2D(2,2))\n",
    "model1e.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1e.add(MaxPooling2D(2,2))\n",
    "model1e.add(Dropout(0.3))\n",
    "\n",
    "model1e.add(Flatten())\n",
    "\n",
    "model1e.add(Dense(128, activation='relu'))\n",
    "model1e.add(Dropout(0.25))\n",
    "model1e.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1e.compile(SGD(learning_rate=0.001, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb1e=callbacks.ModelCheckpoint('m1ecp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - 20s 87ms/step - loss: 0.7950 - accuracy: 0.6125 - val_loss: 0.4261 - val_accuracy: 0.7164\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42612, saving model to m1ecp.h5\n",
      "Epoch 2/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.4961 - accuracy: 0.7731 - val_loss: 0.2145 - val_accuracy: 0.8004\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42612 to 0.21454, saving model to m1ecp.h5\n",
      "Epoch 3/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.3545 - accuracy: 0.8472 - val_loss: 0.3539 - val_accuracy: 0.8166\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.21454\n",
      "Epoch 4/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.2642 - accuracy: 0.8864 - val_loss: 0.5075 - val_accuracy: 0.8503\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21454\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 5/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.2167 - accuracy: 0.9167 - val_loss: 0.3165 - val_accuracy: 0.8835\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21454\n",
      "Epoch 6/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.1834 - accuracy: 0.9306 - val_loss: 0.2109 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.21454 to 0.21086, saving model to m1ecp.h5\n",
      "Epoch 7/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.1836 - accuracy: 0.9308 - val_loss: 0.0770 - val_accuracy: 0.8838\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21086 to 0.07698, saving model to m1ecp.h5\n",
      "Epoch 8/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.1853 - accuracy: 0.9272 - val_loss: 0.7065 - val_accuracy: 0.8829\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07698\n",
      "Epoch 9/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.1777 - accuracy: 0.9331 - val_loss: 0.3228 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07698\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "Epoch 10/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.1715 - accuracy: 0.9325 - val_loss: 0.4014 - val_accuracy: 0.8663\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07698\n",
      "Epoch 11/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.1727 - accuracy: 0.9333 - val_loss: 0.2191 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.07698\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 12/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.1686 - accuracy: 0.9403 - val_loss: 0.0508 - val_accuracy: 0.8666\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.07698 to 0.05080, saving model to m1ecp.h5\n",
      "Epoch 13/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.1725 - accuracy: 0.9325 - val_loss: 0.1995 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.05080\n",
      "Epoch 14/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.1720 - accuracy: 0.9333 - val_loss: 0.3661 - val_accuracy: 0.8666\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05080\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "Epoch 15/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.1711 - accuracy: 0.9383 - val_loss: 0.1348 - val_accuracy: 0.8662\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05080\n",
      "Epoch 16/20\n",
      "225/225 [==============================] - 19s 83ms/step - loss: 0.1714 - accuracy: 0.9339 - val_loss: 0.2043 - val_accuracy: 0.8671\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.05080\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-13.\n",
      "Epoch 17/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.1691 - accuracy: 0.9372 - val_loss: 0.4975 - val_accuracy: 0.8662\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05080\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1e=model1e.fit_generator(train_set1d,\n",
    "                             steps_per_epoch=3600//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set1d,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1d,cb1e,ro1d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "model2.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "model2.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model2.compile(SGD(learning_rate=0.01, momentum=0.9, nesterov='True'), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set2 = train_datagen.flow_from_directory('assign_3_data/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set2 = test_datagen.flow_from_directory('assign_3_data/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb2=callbacks.ModelCheckpoint('m2cp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es2= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=4,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro2=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.6728 - accuracy: 0.6700 - val_loss: 0.1671 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16714, saving model to m2cp.h5\n",
      "Epoch 2/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.2784 - accuracy: 0.8839 - val_loss: 0.1631 - val_accuracy: 0.9669\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16714 to 0.16307, saving model to m2cp.h5\n",
      "Epoch 3/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.1649 - accuracy: 0.9306 - val_loss: 0.0095 - val_accuracy: 0.9336\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16307 to 0.00955, saving model to m2cp.h5\n",
      "Epoch 4/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.1149 - accuracy: 0.9553 - val_loss: 0.2390 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00955\n",
      "Epoch 5/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.0888 - accuracy: 0.9625 - val_loss: 0.1224 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00955\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999776482583e-05.\n",
      "Epoch 6/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.0925 - accuracy: 0.9669 - val_loss: 0.1603 - val_accuracy: 0.9664\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00955\n",
      "Epoch 7/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.0283 - val_accuracy: 0.9499\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00955\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "history2=model2.fit_generator(train_set2,\n",
    "                             steps_per_epoch=3600//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set2,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es2,cb2,ro2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model3.add(MaxPooling2D(2,2))\n",
    "model3.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model3.add(MaxPooling2D(2,2))\n",
    "model3.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model3.add(MaxPooling2D(2,2))\n",
    "model3.add(Dropout(0.3))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model3.compile(RMSprop(), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb3=callbacks.ModelCheckpoint('m3cp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.6231 - accuracy: 0.7511 - val_loss: 0.3035 - val_accuracy: 0.8662\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30354, saving model to m3cp.h5\n",
      "Epoch 2/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.2060 - accuracy: 0.9236 - val_loss: 0.0813 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30354 to 0.08134, saving model to m3cp.h5\n",
      "Epoch 3/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.1166 - accuracy: 0.9600 - val_loss: 0.4850 - val_accuracy: 0.9331\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08134\n",
      "Epoch 4/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.0698 - accuracy: 0.9783 - val_loss: 0.0096 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08134 to 0.00955, saving model to m3cp.h5\n",
      "Epoch 5/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 1.2901 - val_accuracy: 0.9667\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00955\n",
      "Epoch 6/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.0387 - accuracy: 0.9881 - val_loss: 1.3873 - val_accuracy: 0.8506\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00955\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 7/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.0867 - accuracy: 0.9794 - val_loss: 0.2201 - val_accuracy: 0.8835\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00955\n",
      "Epoch 8/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.3959 - val_accuracy: 0.8999\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00955\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "history3=model3.fit_generator(train_set2,\n",
    "                             steps_per_epoch=3600//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set2,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es2,cb3,ro2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4=Sequential()\n",
    "model4.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model4.add(MaxPooling2D(2,2))\n",
    "model4.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model4.add(MaxPooling2D(2,2))\n",
    "model4.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model4.add(MaxPooling2D(2,2))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Flatten())\n",
    "\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model4.compile(Adam(), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb4=callbacks.ModelCheckpoint('m4cp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.5584 - accuracy: 0.7469 - val_loss: 0.0973 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09731, saving model to m4cp.h5\n",
      "Epoch 2/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.2015 - accuracy: 0.9178 - val_loss: 0.0085 - val_accuracy: 0.9666\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09731 to 0.00853, saving model to m4cp.h5\n",
      "Epoch 3/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.1125 - accuracy: 0.9592 - val_loss: 0.0297 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00853\n",
      "Epoch 4/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.0588 - accuracy: 0.9769 - val_loss: 0.0162 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00853\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 5/20\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 0.0804 - accuracy: 0.9744 - val_loss: 0.1381 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00853\n",
      "Epoch 6/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 0.1747 - val_accuracy: 0.9666\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00853\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "history4=model4.fit_generator(train_set2,\n",
    "                             steps_per_epoch=3600//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set2,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es2,cb4,ro2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5=Sequential()\n",
    "model5.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model5.add(MaxPooling2D(2,2))\n",
    "model5.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model5.add(MaxPooling2D(2,2))\n",
    "model5.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model5.add(MaxPooling2D(2,2))\n",
    "model5.add(Dropout(0.3))\n",
    "\n",
    "model5.add(Flatten())\n",
    "\n",
    "model5.add(Dense(128, activation='relu'))\n",
    "model5.add(Dropout(0.25))\n",
    "model5.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model5.compile(Nadam(), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb5=callbacks.ModelCheckpoint('m5cp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.7917 - accuracy: 0.7175 - val_loss: 0.2150 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21497, saving model to m5cp.h5\n",
      "Epoch 2/20\n",
      "225/225 [==============================] - 19s 85ms/step - loss: 0.3154 - accuracy: 0.8844 - val_loss: 0.2523 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.21497\n",
      "Epoch 3/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.1337 - accuracy: 0.9444 - val_loss: 0.0027 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21497 to 0.00268, saving model to m5cp.h5\n",
      "Epoch 4/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.0655 - accuracy: 0.9742 - val_loss: 0.4494 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00268\n",
      "Epoch 5/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.0347 - val_accuracy: 0.9502\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00268\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 6/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.0362 - accuracy: 0.9892 - val_loss: 0.0392 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00268\n",
      "Epoch 7/20\n",
      "225/225 [==============================] - 19s 86ms/step - loss: 0.0312 - accuracy: 0.9906 - val_loss: 0.3614 - val_accuracy: 0.9328\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00268\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-07.\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "history5=model5.fit_generator(train_set2,\n",
    "                             steps_per_epoch=3600//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set2,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es2,cb5,ro2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD took around 8 to 10 epochs to converge, while Nesterov Accelerated gradient converged in lesser steps. RMSprop convrged in 5 epochs while Adam and Nadam took only 3 to 4 epochs for the model to converge. Also, the initial accuracy was higher in RMSprop, Adam and Nadam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll load two models (having minimum loss):\n",
    "# model1d (SGD) and\n",
    "# model4 (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = load_model('m1dcp.h5')\n",
    "model_b = load_model('m4cp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model,img_string):\n",
    "    image=cv2.imread(img_string)\n",
    "    image=cv2.resize(image,(200,200),interpolation=cv2.INTER_AREA)\n",
    "    image=image.reshape(1,200,200,3)\n",
    "    res=model.predict_classes(image, 1, verbose=0)[0]\n",
    "    if res==0:\n",
    "        pred='Saree'\n",
    "    if res==1:\n",
    "        pred='Shirt'\n",
    "    if res==2:\n",
    "        pred='Tshirt'\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saree'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model_a, 'saree.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shirt'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model_a, 'shirt.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shirt'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model_b, 'shirt2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tshirt'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model_a, 'tshirt.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
